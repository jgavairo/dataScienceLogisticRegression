# Logistic Regression - Hogwarts House Prediction

Ce projet implÃ©mente une rÃ©gression logistique pour prÃ©dire la maison de Poudlard (Hogwarts) d'un Ã©tudiant en utilisant ses notes dans diffÃ©rentes matiÃ¨res.

## ï¿½ Quick Start

### 1. Setup (First time only)
```bash
python3 setup.py
```
Ce script va :
- VÃ©rifier la version de Python
- VÃ©rifier les dÃ©pendances (pandas, numpy, matplotlib)
- CrÃ©er les dossiers nÃ©cessaires
- VÃ©rifier la prÃ©sence des datasets
- PrÃ©parer l'environnement

### 2. Train the model
```bash
python3 logreg_train.py
```

### 3. Make predictions
```bash
python3 logreg_predict.py
```

### 4. Check results
```bash
head output/houses.csv
```

## ğŸ“ Structure du Projet

```
.
â”œâ”€â”€ logreg_train.py          # Script principal d'entraÃ®nement
â”œâ”€â”€ logreg_predict.py        # Script principal de prÃ©diction
â”œâ”€â”€ setup.py                 # Script de configuration initiale
â”œâ”€â”€ README.md                # Ce fichier
â”‚
â”œâ”€â”€ datasets/                # DonnÃ©es brutes
â”‚   â”œâ”€â”€ dataset_train.csv    # Dataset d'entraÃ®nement
â”‚   â””â”€â”€ dataset_test.csv     # Dataset de test
â”‚
â”œâ”€â”€ output/                  # Fichiers gÃ©nÃ©rÃ©s
â”‚   â”œâ”€â”€ weights.csv          # Poids du modÃ¨le entraÃ®nÃ©
â”‚   â”œâ”€â”€ normalization_params.csv  # ParamÃ¨tres de normalisation
â”‚   â””â”€â”€ houses.csv           # PrÃ©dictions finales
â”‚
â”œâ”€â”€ data_visualization/      # Scripts de visualisation
â”‚   â”œâ”€â”€ describe.py
â”‚   â”œâ”€â”€ histogram.py
â”‚   â”œâ”€â”€ pair_plot.py
â”‚   â””â”€â”€ scatter_plot.py
â”‚
â””â”€â”€ utils/                   # Utilitaires
    â”œâ”€â”€ preprocess.py        # Fonctions de preprocessing
    â”œâ”€â”€ pipeline.py          # Pipeline automatique
    â”œâ”€â”€ prepare_test_data.py
    â””â”€â”€ check_prerequisites.py
```

## ğŸ“– Scripts Principaux

### `logreg_train.py`
**EntraÃ®ne le modÃ¨le de rÃ©gression logistique**

FonctionnalitÃ©s :
- Charge `dataset_train.csv`
- Remplit automatiquement les valeurs manquantes (avec moyennes)
- Normalise les donnÃ©es (z-score: `(x - mean) / std`)
- Ajoute le biais (colonne de 1)
- EntraÃ®ne 4 classificateurs binaires (One-vs-All)
- Utilise la descente de gradient pour optimiser les poids
- Sauvegarde `output/weights.csv` et `output/normalization_params.csv`

**Utilisation :**
```bash
python3 logreg_train.py
# ou avec un chemin custom :
python3 logreg_train.py datasets/dataset_train.csv
```

### `logreg_predict.py`
**Fait des prÃ©dictions sur le dataset de test**

FonctionnalitÃ©s :
- Charge `dataset_test.csv`
- PrÃ©processe automatiquement (fill missing + normalize avec les paramÃ¨tres du train)
- Ajoute le biais
- Utilise les poids entraÃ®nÃ©s pour prÃ©dire
- Applique One-vs-All : choisit la maison avec la probabilitÃ© maximale
- Sauvegarde `output/houses.csv`

**Utilisation :**
```bash
python3 logreg_predict.py
```

**Sortie :**
```csv
Index,Hogwarts House
0,Hufflepuff
1,Ravenclaw
2,Gryffindor
...
```

### `setup.py`
**Configure l'environnement du projet**

VÃ©rifie :
- Version de Python (3.8+)
- DÃ©pendances installÃ©es (pandas, numpy, matplotlib)
- PrÃ©sence des datasets
- PrÃ©sence des scripts
- CrÃ©e les dossiers nÃ©cessaires

**Utilisation :**
```bash
python3 setup.py
```

## ğŸ§® Algorithme

### RÃ©gression Logistique One-vs-All
Module utilitaire contenant les fonctions de preprocessing :
- `load_normalization_params()` - Charge les paramÃ¨tres de normalisation
- `clean_and_normalize()` - Nettoie et normalise les donnÃ©es
- `add_bias()` - Ajoute la colonne de biais
- `load_and_preprocess_test_data()` - Pipeline complet pour les donnÃ©es de test

#### 6. **pipeline.py**
Script orchestrateur qui exÃ©cute tout le pipeline automatiquement.

**Utilisation :**
```bash
python3 pipeline.py
```

**Options :**
1. Pipeline complet (entraÃ®nement + prÃ©diction)
2. PrÃ©diction rapide (utilise le modÃ¨le existant)
3. EntraÃ®nement uniquement
4. Quitter

## ğŸš€ Guide d'Utilisation Rapide

### Option 1 : Pipeline Automatique
```bash
python3 pipeline.py
# Choisir l'option 1 pour tout exÃ©cuter
```

### Option 2 : Ã‰tape par Ã‰tape

#### EntraÃ®nement
```bash
# Ã‰tape 1 : Remplir les valeurs manquantes
python3 fill_missing_values.py

# Ã‰tape 2 : Normaliser les donnÃ©es
python3 normalize_data.py

# Ã‰tape 3 : EntraÃ®ner le modÃ¨le
python3 train_model.py
```

#### PrÃ©diction
```bash
# Faire des prÃ©dictions sur le dataset de test
python3 predict.py
```

## ğŸ§® Algorithme de RÃ©gression Logistique

### Approche One-vs-All
Pour classifier 4 maisons, on entraÃ®ne 4 modÃ¨les binaires :
- Gryffindor vs All
- Hufflepuff vs All
- Ravenclaw vs All
- Slytherin vs All

### Descente de Gradient
Pour chaque modÃ¨le, on itÃ¨re :

1. **Produit scalaire** : `Z = X Â· Î¸`
2. **Activation (SigmoÃ¯de)** : `H = 1 / (1 + e^(-Z))`
3. **Calcul du gradient** : `Gradient = (1/m) * (X^T Â· (H - y))`
4. **Mise Ã  jour** : `Î¸ = Î¸ - (learning_rate Ã— Gradient)`

### Features UtilisÃ©es
Les 10 matiÃ¨res sÃ©lectionnÃ©es :
- Astronomy
- Herbology
- Divination
- Muggle Studies
- Ancient Runes
- History of Magic
- Transfiguration
- Potions
- Charms
- Flying

## ğŸ“Š Fichiers de Sortie

### weights.csv
Contient les poids optimisÃ©s pour chaque maison.
- Lignes : Features (Bias + 10 matiÃ¨res)
- Colonnes : Maisons (Gryffindor, Hufflepuff, Ravenclaw, Slytherin)

### houses.csv
Contient les prÃ©dictions finales :
- Colonne 1 : Index de l'Ã©tudiant
- Colonne 2 : Maison prÃ©dite

## ğŸ”§ ParamÃ¨tres Ajustables

Dans `train_model.py`, fonction `main()` :
- `learning_rate` : Taux d'apprentissage (dÃ©faut : 0.1)
- `max_iter` : Nombre d'itÃ©rations (dÃ©faut : 1000)

## ğŸ“ Notes Importantes

1. **Ordre des opÃ©rations** : Toujours suivre l'ordre :
   - Fill missing values â†’ Normalize â†’ Train
   
2. **Consistency** : Les donnÃ©es de test doivent Ãªtre prÃ©processÃ©es avec les **mÃªmes paramÃ¨tres** que les donnÃ©es d'entraÃ®nement (mean et std sauvegardÃ©s).

3. **Biais** : La colonne de biais (1) est essentielle pour permettre au modÃ¨le d'avoir un terme d'ordonnÃ©e Ã  l'origine.

## ğŸ¯ Ã‰valuation

Pour Ã©valuer les performances, comparez `houses.csv` avec les vraies Ã©tiquettes (si disponibles) en calculant l'accuracy :

```python
accuracy = (nombre_de_prÃ©dictions_correctes) / (nombre_total_de_prÃ©dictions)
```

## ğŸ“š DÃ©pendances

- pandas
- numpy

Installation :
```bash
pip install pandas numpy
```

## ğŸ“ Auteur

Projet de Data Science - RÃ©gression Logistique
